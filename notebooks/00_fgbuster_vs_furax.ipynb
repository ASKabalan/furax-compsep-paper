{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FGBuster and Furax Imports for Component Separation\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/your-notebook.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FGBUSTER IMPORTS\n",
    "import operator\n",
    "from functools import partial\n",
    "\n",
    "# FURAX IMPORTS\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jaxopt\n",
    "from fgbuster import (\n",
    "    CMB,\n",
    "    Dust,\n",
    "    Synchrotron,\n",
    "    basic_comp_sep,\n",
    "    get_instrument,\n",
    ")\n",
    "from furax import HomothetyOperator\n",
    "from furax.obs.landscapes import Stokes\n",
    "from furax.obs.operators import (\n",
    "    CMBOperator,\n",
    "    DustOperator,\n",
    "    MixingMatrixOperator,\n",
    "    SynchrotronOperator,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Sky Maps Creation Using PySM\n",
    "\n",
    "In this section, we create simulated sky maps using the `PySM` library with specified parameters for each astrophysical component. Key elements:\n",
    "\n",
    "- **NSIDE**: Sets the HEALPix resolution, determining the number of pixels in the sky map.\n",
    "- **Reference Frequencies**:\n",
    "  - **Dust** at 150 GHz\n",
    "  - **Synchrotron** at 20 GHz\n",
    "- **Instrument Configuration**: Using the `LiteBIRD` instrument model to simulate observed frequency maps.\n",
    "\n",
    "This setup provides the mixed sky maps required for component separation, with the shape of the output maps indicated for verification.\n",
    "\n",
    "`generate_maps` is used on Jean-Zay to cache the frequency maps on the front node since there is no internet access in the slurm nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded freq_maps for nside 32 from cache.\n"
     ]
    }
   ],
   "source": [
    "from generate_maps import save_to_cache\n",
    "\n",
    "nsides = [32]\n",
    "for nside in nsides:\n",
    "    save_to_cache(nside)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded freq_maps for nside 32 from cache.\n",
      "freq_maps shape: (15, 3, 12288)\n"
     ]
    }
   ],
   "source": [
    "from generate_maps import load_from_cache\n",
    "\n",
    "nside = 32\n",
    "\n",
    "nu, freq_maps = load_from_cache(nside)\n",
    "# Check the shape of freq_maps\n",
    "print(\"freq_maps shape:\", freq_maps.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furax expects a `Stokes` object as input, so we convert the frequency maps to the correct format, so we transform the `freq_maps` into a `Stokes` object to make it compatible with Furax.\n",
    "\n",
    "__Note__: Although Furax includes its own functions to create sky maps from PySM, we use `fgbuster` here to ensure that both methods receive identical inputs for comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StokesIQU(i=ShapeDtypeStruct(shape=(15, 12288), dtype=float64), q=ShapeDtypeStruct(shape=(15, 12288), dtype=float64), u=ShapeDtypeStruct(shape=(15, 12288), dtype=float64))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Stokes.from_stokes(I=freq_maps[:, 0, :], Q=freq_maps[:, 1, :], U=freq_maps[:, 2, :])\n",
    "d.structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dust_nu0 = 150.0\n",
    "synchrotron_nu0 = 20.0\n",
    "instrument = get_instrument(\"LiteBIRD\")\n",
    "components = [CMB(), Dust(dust_nu0), Synchrotron(synchrotron_nu0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Likelihood Function for Component Separation\n",
    "\n",
    "In this cell, we define the `negative_log_prob` function, which calculates the negative log-likelihood of observing the given data `d` based on the model parameters.\n",
    "\n",
    "The likelihood function is based on a quadratic form that includes the mixing matrix `A`, inverse noise covariance `N^{-1}`, and observed data `d`. The key term in the likelihood is:\n",
    "\n",
    "$$\n",
    "\\left(A^T N^{-1} d\\right)^T \\left(A^T N^{-1} A\\right)^{-1} \\left(A^T N^{-1} d\\right)\n",
    "$$\n",
    "\n",
    "### Explanation of Each Term\n",
    "\n",
    "1. **$A$**: The mixing matrix operator, which maps the component space to the observed frequency space.\n",
    "2. **$N^{-1}$**: The inverse of the noise covariance matrix, represented by `invN` in the code.\n",
    "3. **$d$**: The observed data, which is structured as a `Stokes` in Furax.\n",
    "\n",
    "### Implementation Details\n",
    "\n",
    "- **Transposing and Applying `A`**: `A.T(d)` applies the transpose of `A` to `d`, equivalent to the term $A^T d$.\n",
    "- **Computing the Likelihood**: The quadratic form is computed by applying $A^T N^{-1} d$, inverting $A^T N^{-1} A$, and performing matrix multiplications to evaluate the likelihood.\n",
    "- **Negative Log-Likelihood**: The final output of `negative_log_prob` is the negative of this log-likelihood value, allowing us to use it as a loss function for optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invN = HomothetyOperator(jnp.ones(1), _in_structure=d.structure)\n",
    "DND = invN(d) @ d\n",
    "\n",
    "in_structure = d.structure_for((d.shape[1],))\n",
    "best_params = {\"temp_dust\": 20.0, \"beta_dust\": 1.54, \"beta_pl\": -3.0}\n",
    "\n",
    "dust_nu0 = 150.0\n",
    "synchrotron_nu0 = 20.0\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def negative_log_prob(params, d):\n",
    "    cmb = CMBOperator(nu, in_structure=in_structure)\n",
    "    dust = DustOperator(\n",
    "        nu,\n",
    "        frequency0=dust_nu0,\n",
    "        temperature=params[\"temp_dust\"],\n",
    "        beta=params[\"beta_dust\"],\n",
    "        in_structure=in_structure,\n",
    "    )\n",
    "    synchrotron = SynchrotronOperator(\n",
    "        nu,\n",
    "        frequency0=synchrotron_nu0,\n",
    "        beta_pl=params[\"beta_pl\"],\n",
    "        in_structure=in_structure,\n",
    "    )\n",
    "\n",
    "    A = MixingMatrixOperator(cmb=cmb, dust=dust, synchrotron=synchrotron)\n",
    "\n",
    "    x = (A.T @ invN)(d)\n",
    "    likelihood = jax.tree.map(lambda a, b: a @ b, x, (A.T @ invN @ A).I(x))\n",
    "    summed_log_prob = jax.tree.reduce(operator.add, likelihood)\n",
    "\n",
    "    return -summed_log_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance of the likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of the nll evaluation\n",
      "65.2 ms ± 7.2 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "Performance of the nll grad evaluation\n",
      "186 ms ± 14.4 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "print(\"Performance of the nll evaluation\")\n",
    "negative_log_prob(best_params, d).block_until_ready()\n",
    "%timeit negative_log_prob(best_params, d).block_until_ready()\n",
    "print(\"Performance of the nll grad evaluation\")\n",
    "jax.grad(negative_log_prob)(best_params, d)[\"beta_pl\"].block_until_ready()\n",
    "%timeit jax.grad(negative_log_prob)(best_params, d)['beta_pl'].block_until_ready()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for Correctness\n",
    "\n",
    "In this cell, we perform a basic correctness check by comparing the gradients of the negative log-likelihood at two sets of parameters:\n",
    "\n",
    "1. **Wrong Parameters**: A set of parameters obtained by adding random noise to `best_params`.\n",
    "2. **Correct Parameters**: The original `best_params`.\n",
    "\n",
    "By calculating and comparing the gradient magnitudes (using the `max` reduction), we can verify that the gradient at the correct parameters is smaller, indicating proximity to an optimal or near-optimal point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrong parameters grad -113186446.19540569\n",
      "Correct parameters grad 154.78784358372695\n"
     ]
    }
   ],
   "source": [
    "wrong_params = jax.tree.map(\n",
    "    lambda x: x + jax.random.normal(jax.random.PRNGKey(0)), best_params\n",
    ")\n",
    "print(\n",
    "    f\"Wrong parameters grad {jax.tree.reduce(max, jax.grad(negative_log_prob)(wrong_params, d))}\"\n",
    ")\n",
    "print(\n",
    "    f\"Correct parameters grad {jax.tree.reduce(max, jax.grad(negative_log_prob)(best_params, d))}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Off the shelf likelihoods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from furax.comp_sep import negative_log_likelihood\n",
    "\n",
    "negative_log_likelihood = partial(\n",
    "    negative_log_likelihood, dust_nu0=dust_nu0, synchrotron_nu0=synchrotron_nu0\n",
    ")\n",
    "\n",
    "L = negative_log_likelihood(best_params, nu=nu, N=invN, d=d)\n",
    "\n",
    "assert jax.tree.all(\n",
    "    jax.tree.map(\n",
    "        lambda x, y: jnp.isclose(x, y, rtol=1e-5), L, negative_log_prob(best_params, d)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validating Against FGBuster: The `c1d0s0` Model\n",
    "\n",
    "In this section, we validate our custom implementation of the likelihood model by comparing it to the `c1d0s0` model from `fgbuster`. By aligning our results with FGBuster’s well-established component separation model, we ensure that our setup and computations are consistent and reliable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1 : Initial Validation: Using `best_params` as the Starting Point\n",
    "\n",
    "We begin the validation process by setting `best_params` as the initial point for both our custom implementation and FGBuster’s `c1d0s0` model. This allows us to directly compare the outputs and confirm that the models produce similar results when initialized wit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dust.beta_d', 'Dust.temp', 'Synchrotron.beta_pl']\n",
      "[ 1.54 20.   -3.  ]\n"
     ]
    }
   ],
   "source": [
    "components[1]._set_default_of_free_symbols(beta_d=1.54, temp=20.0)\n",
    "components[2]._set_default_of_free_symbols(beta_pl=-3.0)\n",
    "\n",
    "result = basic_comp_sep(components, instrument, freq_maps)\n",
    "print(result.params)\n",
    "print(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassim/micromamba/envs/fg/lib/python3.11/site-packages/jaxopt/_src/scipy_wrappers.py:343: OptimizeWarning: Unknown solver options: maxiter\n",
      "  res = osp.optimize.minimize(scipy_fun, jnp_to_onp(init_params, self.dtype),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'beta_dust': Array(1.53999987, dtype=float64),\n",
       " 'beta_pl': Array(-3., dtype=float64),\n",
       " 'temp_dust': Array(19.9999997, dtype=float64)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = {\"temp_dust\": 20.0, \"beta_dust\": 1.54, \"beta_pl\": -3.0}\n",
    "\n",
    "scipy_solver = jaxopt.ScipyMinimize(\n",
    "    fun=negative_log_likelihood, method=\"TNC\", jit=True, tol=1e-10\n",
    ")\n",
    "result = scipy_solver.run(best_params, nu=nu, N=invN, d=d)\n",
    "result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2 : Validation with Incorrect Parameter: Setting `beta_dust` to a Wrong Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<lambdifygenerated-9>:2: RuntimeWarning: overflow encountered in power\n",
      "  return 568.8620443215493*(0.05*nu)**beta_pl*numpy.expm1(0.01760867023799751*nu)**2*exp(-0.01760867023799751*nu)/(nu**2*numpy.expm1(0.3521734047599502)**2)\n",
      "<lambdifygenerated-9>:2: RuntimeWarning: overflow encountered in power\n",
      "  return 568.8620443215493*(0.05*nu)**beta_pl*numpy.expm1(0.01760867023799751*nu)**2*exp(-0.01760867023799751*nu)/(nu**2*numpy.expm1(0.3521734047599502)**2)\n",
      "<lambdifygenerated-10>:2: RuntimeWarning: overflow encountered in power\n",
      "  return 568.8620443215493*(0.05*nu)**beta_pl*numpy.expm1(0.01760867023799751*nu)**2*exp(-0.01760867023799751*nu)*log(0.05*nu)/(nu**2*numpy.expm1(0.3521734047599502)**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD of A failed -> logL = -inf\n",
      "SVD of A failed -> logL_dB not updated\n",
      "SVD of A failed -> logL = -inf\n",
      "SVD of A failed -> logL = -inf\n",
      "SVD of A failed -> logL = -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<lambdifygenerated-9>:2: RuntimeWarning: overflow encountered in multiply\n",
      "  return 568.8620443215493*(0.05*nu)**beta_pl*numpy.expm1(0.01760867023799751*nu)**2*exp(-0.01760867023799751*nu)/(nu**2*numpy.expm1(0.3521734047599502)**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD of A failed -> logL = -inf\n",
      "SVD of A failed -> logL = -inf\n",
      "SVD of A failed -> logL = -inf\n",
      "['Dust.beta_d', 'Dust.temp', 'Synchrotron.beta_pl']\n",
      "[ 1.53194524 19.97377854 -2.9430962 ]\n"
     ]
    }
   ],
   "source": [
    "components[1]._set_default_of_free_symbols(beta_d=2.54, temp=20.0)\n",
    "components[2]._set_default_of_free_symbols(beta_pl=-3.0)\n",
    "\n",
    "result = basic_comp_sep(components, instrument, freq_maps)\n",
    "print(result.params)\n",
    "print(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassim/micromamba/envs/fg/lib/python3.11/site-packages/jaxopt/_src/scipy_wrappers.py:343: OptimizeWarning: Unknown solver options: maxiter\n",
      "  res = osp.optimize.minimize(scipy_fun, jnp_to_onp(init_params, self.dtype),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'beta_dust': Array(1.53999179, dtype=float64),\n",
       " 'beta_pl': Array(-2.9999352, dtype=float64),\n",
       " 'temp_dust': Array(20.00027089, dtype=float64)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"temp_dust\": 20.0, \"beta_dust\": 2.54, \"beta_pl\": -3.0}\n",
    "\n",
    "scipy_solver = jaxopt.ScipyMinimize(\n",
    "    fun=negative_log_likelihood, method=\"TNC\", jit=True, tol=1e-10\n",
    ")\n",
    "result = scipy_solver.run(params, nu=nu, N=invN, d=d)\n",
    "result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3 : Setting `beta_dust` and `beta_pl` to Incorrect Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<lambdifygenerated-9>:2: RuntimeWarning: overflow encountered in power\n",
      "  return 568.8620443215493*(0.05*nu)**beta_pl*numpy.expm1(0.01760867023799751*nu)**2*exp(-0.01760867023799751*nu)/(nu**2*numpy.expm1(0.3521734047599502)**2)\n",
      "<lambdifygenerated-9>:2: RuntimeWarning: overflow encountered in power\n",
      "  return 568.8620443215493*(0.05*nu)**beta_pl*numpy.expm1(0.01760867023799751*nu)**2*exp(-0.01760867023799751*nu)/(nu**2*numpy.expm1(0.3521734047599502)**2)\n",
      "<lambdifygenerated-10>:2: RuntimeWarning: overflow encountered in power\n",
      "  return 568.8620443215493*(0.05*nu)**beta_pl*numpy.expm1(0.01760867023799751*nu)**2*exp(-0.01760867023799751*nu)*log(0.05*nu)/(nu**2*numpy.expm1(0.3521734047599502)**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD of A failed -> logL = -inf\n",
      "SVD of A failed -> logL_dB not updated\n",
      "SVD of A failed -> logL = -inf\n",
      "SVD of A failed -> logL = -inf\n",
      "SVD of A failed -> logL = -inf\n",
      "SVD of A failed -> logL = -inf\n",
      "SVD of A failed -> logL = -inf\n",
      "SVD of A failed -> logL = -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<lambdifygenerated-9>:2: RuntimeWarning: overflow encountered in multiply\n",
      "  return 568.8620443215493*(0.05*nu)**beta_pl*numpy.expm1(0.01760867023799751*nu)**2*exp(-0.01760867023799751*nu)/(nu**2*numpy.expm1(0.3521734047599502)**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dust.beta_d', 'Dust.temp', 'Synchrotron.beta_pl']\n",
      "[ 1.53034346 19.97418092 -5.99479857]\n"
     ]
    }
   ],
   "source": [
    "components[1]._set_default_of_free_symbols(beta_d=2.54, temp=20.0)\n",
    "components[2]._set_default_of_free_symbols(beta_pl=-6.0)\n",
    "\n",
    "result = basic_comp_sep(components, instrument, freq_maps)\n",
    "print(result.params)\n",
    "print(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassim/micromamba/envs/fg/lib/python3.11/site-packages/jaxopt/_src/scipy_wrappers.py:343: OptimizeWarning: Unknown solver options: maxiter\n",
      "  res = osp.optimize.minimize(scipy_fun, jnp_to_onp(init_params, self.dtype),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'beta_dust': Array(1.53999777, dtype=float64),\n",
       " 'beta_pl': Array(-3.00011661, dtype=float64),\n",
       " 'temp_dust': Array(20.0001393, dtype=float64)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"temp_dust\": 20.0, \"beta_dust\": 2.54, \"beta_pl\": -6.0}\n",
    "\n",
    "scipy_solver = jaxopt.ScipyMinimize(\n",
    "    fun=negative_log_likelihood, method=\"TNC\", jit=True, tol=1e-10\n",
    ")\n",
    "result = scipy_solver.run(params, nu=nu, N=invN, d=d)\n",
    "result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 4 : Setting All Parameters to Incorrect Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Dust.beta_d', 'Dust.temp', 'Synchrotron.beta_pl']\n",
      "[ 1.54000008 19.99999732 -3.00000111]\n"
     ]
    }
   ],
   "source": [
    "components[1]._set_default_of_free_symbols(beta_d=2.54, temp=25.0)\n",
    "components[2]._set_default_of_free_symbols(beta_pl=-6.0)\n",
    "\n",
    "result = basic_comp_sep(components, instrument, freq_maps)\n",
    "print(result.params)\n",
    "print(result.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wassim/micromamba/envs/fg/lib/python3.11/site-packages/jaxopt/_src/scipy_wrappers.py:343: OptimizeWarning: Unknown solver options: maxiter\n",
      "  res = osp.optimize.minimize(scipy_fun, jnp_to_onp(init_params, self.dtype),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'beta_dust': Array(1.53999768, dtype=float64),\n",
       " 'beta_pl': Array(-2.99996799, dtype=float64),\n",
       " 'temp_dust': Array(20.00007388, dtype=float64)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"temp_dust\": 25.0, \"beta_dust\": 2.54, \"beta_pl\": -6.0}\n",
    "\n",
    "scipy_solver = jaxopt.ScipyMinimize(\n",
    "    fun=negative_log_likelihood, method=\"TNC\", jit=True, tol=1e-10\n",
    ")\n",
    "result = scipy_solver.run(params, nu=nu, N=invN, d=d)\n",
    "result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Optax optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "import optax.tree_utils as otu\n",
    "from jax_grid_search import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final parameters: {'beta_dust': Array(1.54000002, dtype=float64), 'beta_pl': Array(-3.0000005, dtype=float64), 'temp_dust': Array(19.99999868, dtype=float64)}, number of evaluations: 39\n",
      "Initial Value: -6114624736980.274\n"
     ]
    }
   ],
   "source": [
    "solver = optax.lbfgs()\n",
    "\n",
    "final_params, final_state = optimize(\n",
    "    params, negative_log_likelihood, solver, max_iter=100, tol=1e-4, nu=nu, N=invN, d=d\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Final parameters: {final_params}, number of evaluations: {otu.tree_get(final_state, 'count')}\"\n",
    ")\n",
    "print(f\"Initial Value: {negative_log_prob(final_params, d=d)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
